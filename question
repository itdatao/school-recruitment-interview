

## `什么是数据库，数据库管理系统，数据库系统，数据库管理员？`

<br />数据库: 数据库简称DB是信息的集合或者说数据库时由数据库管理系统管理的数据的集合。<br />
<br />数据库管理系统：数据库管理系统简称DBMS是一种操作和管理数据库的大型软件，通常用于建立，使用和维护数据库。<br />
<br />数据库系统：数据库系统简称DBS，通常由软件，数据库和数据管理员组成。<br />
<br />数据库管理员：数据库管理员简称DBA，负责管理和控制数据库。<br />

## `什么是元组，码，候选码，主码，外码，主属性，非主属性？`

<br />**元组：**元组是关系型数据库中的基本概念，关系是一张表，表中的每行就是一个元组，每列代表一个属性，在二维表里，元组也称为行。<br />
<br />**码：**码是能唯一标识实体的属性，对应表中的列。<br />
<br />**候选码：**若关系中的某一属性或属性组的值能唯一标识一个元组，而其他任何，子集都不能标识，则该属性组是候选码。例如：在学生实体中，“学号”是能唯一的区分学生实体的，同时又假设“姓名”、“班级”的属性组合足以区分学生实体，那么{学号}和{姓名，班级}都是候选码。<br />
<br />**主码：**主键，是候选码中选出来的，一个实体集中只能有一个主键，可以有多个候选码。<br />
<br />**主属性：**候选码中出现过的属性称为主属性，比如关系工人（工号，身份证号码，姓名，性别）显然工号和身份证号都能够唯一标识这个关系，所以都是候选码。工号和身份证号就是主属性，如果主键是一个属性组，那么这个属性组都是主属性。<br />
<br />**非主属性：**不包含在任何一个候选码中的属性称为非主属性。比如在关系——学生（学号，姓名，年龄，性别，班级）中，主码是“学号”，那么其他的“姓名”、“年龄”、“性别”、“班级”就都可以称为非主属性。<br />

## `主键和外键有什么区别？`

<br />主键：主键永远忽唯一标识一个元组，不能有重复，不允许为空，一个表中只能有一个主键。<br />
<br />外键：外键用来和其他表建立练习，外键是另一个表的主键，外键是可以有重复的，可以为空，一个表中可以有多个外键。<br />

## `讲讲数据库范式`

<br />第一范式：属性不可再分<br />
<br />第二范式：在第一范式的基础上，消除了非主属性对于码的部分函数依赖<br />
<br />第三范式：在第二范式的基础上。消除了非主属性对于码的传递函数依赖<br />

## `什么是函数依赖？什么是部分函数依赖，传递函数依赖，完全函数依赖`

<br />函数依赖：如果在一张表中，属性x的值确定的情况下，必定能确定属性y的值，说明y依赖x，写作：x->y<br />
<br />部分函数依赖：如果x->y,并且存在x的真子集x0，使得x0->y，则称y对x部分函数依赖。<br />
<br />完全函数依赖：在一个关系中，若某个非主属性数据项依赖于全部关键字称为完全函数依赖。<br />
<br />传递函数依赖：在关系模式R中，假设X,Y,Z是U的不同的属性子集，如果X 确定Y，Y确定Z，且X不包含Y，Y不确定X ，（X∪Y）∩Z=空集合，则Z传递函数依赖于X。比如在关系R(学号 ,姓名, 系名，系主任)中，学号 → 系名，系名 → 系主任，所以存在非主属性系主任对于学号的传递函数依赖。。<br />

## `什么是存储过程？`

<br />存储过程可以看做SQL语句的集合，中间加入一些逻辑控制语句。存储过程在业务比较复杂的时候是很实用的。比如完成一个操作需要写许多SQL语句，这时候我们可以写一个存储过程，这样就方便了下一次调用，使用存储过程比单独的SQL执行要快，因为存储过程是预编译的。但是存储过程难以调试和扩展，没有移植性，还会消耗数据库资源。<br />

## `drop，delete，truncate的区别`

<br />**执行结果不同，用法不同**<br />
<br />drop table表名，直接删除表；<br />
<br />truncate 表名，只删除表中的数据，在初入数据的时候如果设置的有自增id，id会从1开始，在清空表的时候使用。<br />
<br />delete from 表名 where 列名=？，删除某一列的值，如果不加条件和truncate执行结果一样，都是清空表数据，不删除表。<br />
<br />drop会删除表结构，truncate和delete只会删除表数据。<br />
<br />**语句类型不同**<br />
<br />truncate和drop属于DDL（数据定义语言），操作后就会生效，不能回滚，操作不触发trigger，delete是DML（数据库操作语言）操作hi放到rollback的segement中，事务提交之后才能生效。<br />
<br />**执行速度不同**<br />
<br />drop>truncate>delete<br />

## `DDL,DML的区别？`

<br />DDL：DDL是数据定义语言，简单来说就是对数据库对象进行创建和删除，修改的语言，操作表结构，视图和索引。他和DML最大的区别是DML只对表中内部的数据进行操作，而不会修改表结构，更不会涉及到其他表对象。DDL更多的被数据库管理员所使用的，一般开发人员很少使用。<br />
<br />DML：是数据库操作语言，对数据库表中记录的操作，主要包括表记录的插入，更新，删除和查询，是开发人员使用最频繁的操作。<br />
<br />DQL：数据库查询语言，select。<br />
<br />DCL：数据控制语言，grant，revoke，commit，rollback。<br />

## `数据库设计的步骤`


1. 需求分析
1. 概念设计 ER图
1. 逻辑结构设计：将ER图转换成表
1. 物理结构设计：为数据库选择合适的存储结构和存取路径
1. 数据库实施：编程，测试和运行
1. 运行和维护



## `事务的ACID特性说下`


1. 原子性：事务是最小的执行单位，不允许分割，事务的原子性确保动作要么全部执行，要么不执行。
1. 一致性：执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的。
1. 隔离性：并发访问数据库，一个用户的事务不被其他事务所干扰，各个并发事务之间数据库时独立的。
1. 持久性：一个事务被提交之后，他对数据库中数据的改变是持久的，即使数据库发生故障页不应该对其有任何影响。



## `并发事务引起了那些问题？`

<br />**脏读：**当一个事务长在访问数据库并且对数据库的数据进行了修改，而这种修改还没提交到数据库在建瓯功能，这时候另一个事务也访问到了这个数据，然后使用了这个数据。因为这个数据没提交，另外这个事物读到的就是脏数据。<br />
<br />**丢失修改：**在一个事务读取一个数据的时候，另外一个事务也访问到了该数据，第一个事务修改了数据，第二个事务也修改了数据，导致第一个事务修改结果被丢失，因此称作丢失修改。<br />
<br />**不可重复读：**指在一个事务内多次读取同一个数据，在这个事务没结束的时候，另一个事务对这条数据进行修改，导致了第一个事务读到的数据和以前读到的数据不一致，因此称为不可重复读。<br />
<br />**幻读：**幻读与不可重复读相似，第一个事务读取几行数据，接着另一事务插入了一些数据，在随后的查询中，第一个事务发现多了一些原本不存在的数据，感觉像幻觉一样，称为幻读。<br />
<br />**不可重复读与幻读的区别**<br />
<br />不可重复读重点在于修改，幻读在于增加和删除。<br />

## `事务的隔离级别有哪些`


- 读未提交：最低的隔离级别，运行读取尚未提交的数据，可能会导致脏读 ，幻读，不可重复读。
- 读已提交：允许读取并发事务已提交的数据，可以阻止脏读，但是会出现不可重复读和幻读。
- 可重复读：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。
- 可串行化：该级别可以防止脏读，幻读，不可重复读。


<br />MySQL InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）**。我们可以通过`SELECT @@tx_isolation;`命令来查看,MySQL 8.0 该命令改为`SELECT @@transaction_isolation;`<br />

```sql
mysql> SELECT @@tx_isolation;
+-----------------+
| @@tx_isolation  |
+-----------------+
| REPEATABLE-READ |
+-----------------+Copy to clipboardErrorCopied
```

<br />这里需要注意的是：与 SQL 标准不同的地方在于InnoDB 存储引擎在 **REPEATABLE-READ（可重读）** 事务隔离级别下，允许应用使用 Next-Key Lock 锁算法来避免幻读的产生。这与其他数据库系统(如 SQL Server)是不同的。所以说虽然 InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）** ，但是可以通过应用加锁读（例如 `select * from table for update` 语句）来保证不会产生幻读，而这个加锁度使用到的机制就是 Next-Key Lock 锁算法。从而达到了 SQL 标准的 **SERIALIZABLE(可串行化)** 隔离级别。<br />
<br />因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是**READ-COMMITTED(读取提交内容): _但是你要知道的是InnoDB 存储引擎默认使用 *_REPEATABLE-READ（可重读）** 并不会有任何性能损失。<br />
<br />InnoDB 存储引擎在 **分布式事务** 的情况下一般会用到**SERIALIZABLE(可串行化)** 隔离级别。

## 事务隔离级别的实现

数据库会创建一个视图，访问的时候以视图的逻辑结果为准。

- 可重复读的隔离级别下，视图是在事务启动时创建的，整个事务存在期间都会用到这个视图（一致性视图MVCC）
- 在读提交的级别下，这个视图是在每个SQL语句开始执行时创建的。（MVCC实现的一致性视图）
- 在读未提交的级别下，会直接返回记录的最新值，没有视图的概念。
- 串行化是直接通过加锁的方式避免并行访问。

## 避免长事务的方法

1. 开发中减少事务范围，少用长事务，如果无法避免，保证逻辑日志空间够用，并且支持日志空间的增长。
1. 监控事务表innodb_trx，发现长事务报警。

查询长事务

```sql
select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```


## `乐观锁和悲观锁的区别？`

<br />**悲观锁**<br />
<br />总是假设最坏的情况下去获取锁，最坏的情况就是认为每次拿数据都会有人修改数据，所以每次获取数据的时候都会加锁，这样别人想要修改这条数据就会阻塞，直到获取数据成功后释放锁。传统的关系型数据库里面就用到了很多这样的锁，比如行锁，表锁，读锁，写锁等，Java中synchronized和ReentrantLock独占锁就是悲观锁的思想。<br />
<br />**乐观锁**<br />
<br />总是假设最好的情况下去拿数据，最好的情况就是拿数据的时候没人会和你抢数据，修改数据，因此不会上锁，但是在更新的时候会判断在此期间别人有没有更新数据，可以使用版本号机制和CAS算法事项。乐观锁使用与读多写少的情况下，这样可以提高吞吐量，向数据库提供的类似于write_condition机制，其实就是提供的乐观锁。Java中atomic原子类就是使用了CAS算法实现的。<br />

## `两种锁的使用场景`

<br />乐观锁适用于写少读多的情况下，这样能省去加锁的开销，加大系统整体的吞吐量。<br />
<br />如果是多写的情况下，一般会产生冲突，这会导致上层应用会不断进行尝试，反而会降低性能，因此多写情况下选用悲观锁较为合适。<br />

## `乐观锁常见的两种实现方式？`


1. 版本号机制：一般会在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version会+1，当线程A要更新数据值时，在读数据的同时也会读取version值，在提交更新时，如果刚才读取的version值和当前数据库中的version相等才会更新，否则重试更新操作，直到更新成功。
1. CAS算法，compare and swap，是一种有名的无锁算法。无锁编程，在不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫做非阻塞同步。


<br />CAS操作三个变量：需要读写的内存值V，进行比较的值A，即将写入的值B。<br />
<br />当且仅当V的值等于A，CAS 通过原子方式用B更新V的值，否则不会执行任何操作，一般情况下是自旋操作，也就是不断的重试。<br />

## `说说乐观锁的缺点`


1. ABA问题


<br />如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到他仍然是A，那我们就能说明他的值一定没被修改过吗？是不能的，因为在这段时间他的值可能被修改之后有改回来了A，那么CAS操作就会认为他从来没被修改过，这个问题被称为ABA问题。<br />

2. 循环时间开销大（消耗CPU资源）


<br />自旋操作如果长时间不成功，就会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率就会有一定的提升，pause指令有两个作用，第一个可以延迟流水线执行指令，使CPU不会消耗过多的执行资源，延迟时间取决于具体实现的版本，在一些处理器上延迟时间是0。第二可以避免在退出循环的时候因内存顺序冲突引起CPU流水线被清空，从而提高CPU的执行效率。<br />

3. 只能保证一个共享变量的原子操作


<br />CAS只对单个共享变量有效，当设计多个共享变量时CAS 无效，但是从JDK1.5开始，提供了AtomicReference类来保证对象之间的原子性，你可以把多个变量放在一个对象里进行CAS操作，所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。<br />

## InnoDB如何解决幻读

在RR级别下采用InnoDB可以解决幻读，引入了间隙锁。<br />幻读：在同一个事务中，前后两次查询范围相同时，得到的结果不一致，后一次查询到新插入的行。<br />在RR级别下，普通读是快照读，幻读仅仅发生在当前读的基础上。

```sql
select * from t where d=0 -- 快照读，对于一个事务来说每次读到的结果是一样的
select * from t where d=0 in share mode |
select * from t where d=0 for update --当前读，总是读取当前数据行的最新数据
```

幻读破坏了语义，导致了数据一致性问题。<br />锁的存在就是为了避免在并发条件下出现一致性问题。因此InnoDB使用间隙锁解决幻读。<br />间隙锁会将行与行之间的空隙锁住。执行for update时不但会将全表锁住还会将间隙锁住。<br />间隙锁仅仅对插入操作本身互斥，不同事务之间的间隙锁并不互斥。<br />间隙锁的引入虽然锁住了更大的范围，但是降低了并发度。<br />如果当前业务需求不需要使用间隙锁，这时可以将隔离级别设置为RC，binlog格式设置成row。<br />binlog的三种格式

- STATEMENT：主库向从库同步时，会将原生的SQL发送给从库。
- ROW：Master会把操作后的表中的行记录在日志中，向从库同步简单的说就是表中的数据。
- MIXED：默认是STATEMENT方式记录，但是在一些情况下会自动切换成ROW的方式。

## `MyISAM和InnoDB的区别有哪些`


- Innodb支持事务，MyISAM不支持事务。
- InnoDB支持外键，MyISAM不支持。
- InnoDB使用的是聚集索引，MyISAM使用的是非聚集索引。聚集索引的文件存放在主键索引的叶子结点上，所以InnoDB必须有主键，通过主键索引查询效率很高。但是辅助索引需要回表操作，两次查询，先查询主键，然后通过主键查数据。所以主键不应该过大，如果主键过大其他索引也都会很大。非聚集索引的话，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。
- InnoDB不保存表的具体行数，`select count(*) from table`需要全表扫描。但是MyISAM用一个变量保存了整个表的行数，执行上述语句只需要读出变量的值就行。
- InnoDB最小的锁粒度是行级锁，MyISAM最小的锁粒度是表级锁。更新语句会锁住整张表，导致其他的查询和更新都会被阻塞，所以并发访问收到很大限制。

|                            | MyISAM                                                       | InnoDB                                                       |
| -------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 存储结构                   | 每张表被存放在三个文件：frm:表结构定义，myd:表数据文件，myi:索引文件 | 所有的表都保存在同一个数据文件中，InnoDB表的大小只收限于操作系统文件的大小。一般是2G。 |
| 存储空间                   | MyISAM可被压缩，存储空间较小                                 | InnoDB的表需要更多的内存，他会在主内存中建立专用的缓冲池用于高速缓冲数据和索引。 |
| 可移植性、备份、恢复       | 由于MyISAM的数据是以文件的形式存储的，所以在跨平台的数据转移中会很方便，备份和恢复时可单独针对某个表进行操作。 | 免费拷贝数据文件，备份binlog，或者用mysqldump，但是当数据量达到几十G的时候很难受 |
| 文件格式                   | 数据存储在`.myd` 索引存储在`.myi`                            | 数据和索引是集中存储的，`ibd`                                |
| 记录存储顺序               | 按照记录的插入顺序保存                                       | 按主键大小有序插入                                           |
| 外键                       | 不支持                                                       | 支持                                                         |
| 事务                       | 不支持                                                       | 支持                                                         |
| 行级锁                     | 不支持                                                       | 支持                                                         |
| select查询效率             | 高                                                           |                                                              |
| insert，update，delete效率 |                                                              | 高                                                           |
| select cout(*)             | 查询效率更高因为内部维护了计数器。直接可获取                 |                                                              |
| 索引实现方式               | B+树索引，MyISAM是堆表                                       | B+树索引，InnoDB是索引组织表                                 |
| 哈希索引                   | 不支持                                                       | 支持                                                         |
| 全文索引                   | 支持                                                         | 不支持                                                       |


<br />MySQL5.5之后默认情况下存储引擎都是InnoDB。<br />

## `MyISAM索引和InnoDB索引的区别`

- InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引。
- InnoDB的主键索引的叶子结点存储着行数据，因此主键索引非常有效。
- MyISAM索引的叶子结点存储的是行数据的地址，需要回表操作才能得到数据。
- InnoDB非主键索引的叶子结点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引查询效率会非常高效。



## `InnoDB的四大特性`


- 插入缓冲
- 二次写
- 预读
- 自适应哈希索引



## `存储引擎的选择`

<br />如果没有特别的需求使用默认的InnoDB就可以。<br />
<br />MyISAM：读写插入为主的应用 程序，比如博客系统，门户网站等。<br />
<br />InnoDB：要保证数据的完整性；并发量高，支持事务和外键，比如OA自动化办公系统。<br />

## `索引的优缺点`

<br />索引的优点<br />

- 可以加快数据的检索速度，这也是创建索引最主要的原因
- 通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能


<br />索引的缺点<br />

- 创建索引，维护索引要耗费时间，具体的，当对表中的数据进行增加删除和修改的时候，索引也要动态的维护，会降低增删改的执行效率
- 空间方面：索引需要占据更多的物理空间



## `索引的类型`


- 主键索引：数据列不允许重复，不允许为null，一个表只能有一个主键
- 唯一索引：数据列不允许重复，允许为null，一个表中允许多个列创建唯一索引。
  - `alter table table_name add unique(cloum);`创建唯一索引
  - `alter table table_name add unique(column1,column2);`创建唯一组合索引
- 普通索引：基本的索引类型，没有唯一性的限制，允许为NULL值
- 全文索引：是目前搜索引擎使用的关键技术
  - `alter table table_name add fulltext(column);`创建全文索引



## `redo/undo log,bin log的定义`

<br />redo log和undo log<br />
<br />redo log是重做日志提供`前滚`操作；<br />
<br />undo log是回退日志，提供`回滚`操作；<br />

## `为什么需要redo log?`

<br />这里扯一下只用undo log实现原子性和持久性的缺陷。<br />

- 事务提交前需要将undo log写磁盘（提供可回滚功能，不保证原子性），这会造成多次磁盘IO，这些是顺序IO。
- 事务提交后需要将数据立即更新到数据库中，这会造成至少一次磁盘IO，这是随机IO。


<br />如果在事务提交后先将数据缓存一段时间，而不是立即更新数据库，这就能减少随机IO，提高性能。但是这样就会丧失事务的持久性。因此引入了另一种机制来实现持久化。既是redo log。redo log解决的问题之一就是事务执行过程中的强制刷新脏数据。<br />
<br />在事务提交之前，只要将redo log持久化即可，不需要将数据持久化。当系统崩溃后，虽然数据没有持久化，但是redo log已经持久化。系统可以根据redo log的内容，将所有数据恢复到最新状态。<br />
<br />redo log是物理日志，记录的是数据页的物理修改而不是某一行或者某几行修改成怎样的。它用来恢复提交后的物理数据页，只能恢复到最后一次提交的位置。数据库启动的时候会根据redo log恢复数据，提升了数据库的吞吐降低了访问时延。<br />
<br />而undo log是用来记录到某个版本。一般是逻辑日志，根据每行数据进行记录。通常记录数据被修改前的值，当事务提交失败后用来回滚事务。<br />
<br />redo log记录某个数据块被修改后的值，可以用来恢复未写入data file的已成功事务更新的数据。<br />
<br />**redo log保证了事务的持久性。**<br />
<br />**undo log保证了事务的原子性。**<br />
<br />假设在数据库提交事务的场景下突然宕机了，这时候有两个事务，一个事务已经提交了，另一个事务还没提交。数据库重启的时候会根据undo log将没有提交的事务进行回滚操作，回滚到提交前的版本，保证数据的原子性。已提交的事务会通过redo log将所有已经在存储引擎内部提交的事务恢复。<br />

## `redo log和undo log与bin log的区别`


- 层次不同。redo/undo是innodb引擎层维护的，但是binlog 是MySQL server层维护的和存储引擎的类别没有关系。记录的是所有引擎的更新操作的日志记录。
- 记录内容不同。redo/undo记录的是每个页/每个数据的修改情况，数据物理日志+逻辑日志结合的方式。binlog记录的是事务操作内容，bin log有三种模式。基于SQL语句的复制（Statement），基于行的复制（Row）以及混合模式（Mixed）。不管采用的是什么模式，文件都是二进制文件。
- 记录的时机不同：redo/undo在事务执行的过程中会不断的写入，而binlog是在事务最终提交前写入的。binlog什么时候刷新到磁盘跟参数`sync_binlog`有关。


<br />`bin log的三种模式有哪些之间的不同点又有哪些`<br />

- statement：基于SQL语句的模式，某些语句中包含一些函数，例如UUID NOW等在复制过程中导致数据不一致甚至出错。
- row：基于行的模式，记录的是行的变化，很安全。但是binlog的磁盘占用会比另外两种模式大很多，在一些答辩中清除大量数据的时候在binlog中回申城很多语句导致延迟变大。
- mixed：混合模式：根据语句来选用SQL模式还是row模式。



## `什么是两阶段提交？`

<br />两阶段提交是为了保证redo log bin log逻辑一致性。<br />
<br />一条update语句执行的流程。浅色表示在InnoDB内部之星，深色框实在执行器中执行的。<br />
<br />![](https://cdn.nlark.com/yuque/0/2021/png/1758561/1616746057010-9130106f-05fb-4210-bf6d-b43fe433cce1.png#align=left&display=inline&height=1522&margin=%5Bobject%20Object%5D&originHeight=1522&originWidth=1142&size=0&status=done&style=none&width=1142)<br />
<br />两阶段提交包含prepare和commit两个阶段。<br />

## 为什么必须有两阶段提交呢？

<br />假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash（擦除），会出现什么情况呢？<br />
<br />如果先写redo log这时候数据库宕机了，binlog未写入，则在主从复制的场景下从库就比主库少了同步的数据造成主从不一致的情况。因此需要内部事务来保证两个日志的一致性。<br />
<br />prepare阶段：redo log写入log buffer，并fsync持久化到磁盘，在redo log事务中记录2PC的XID，在redo log事务打上prepare标识。<br />commit阶段：bin log写入log buffer，并fsync持久化到磁盘，在bin log事务中记录2PC的XID，同时在redo log事务打上commit标识。<br />其中，prepare和commit阶段所提到的“事务”，都是指内部XA事务，即2PC。<br />
<br />checkpoint<br />
<br />当遇到内存不足，db buffer已满的时候，需要将db buffer中的内容或者部分内容转储到data file中。在转储过程中，会记录发生的时刻（checkpoint)。在故障恢复的时候，只需要redo/undo最近一次的checkpoint之后的操作。<br />

## `MVCC解决了那些问题？具体实现原理是什么？`

<br />什么是MVCC<br />全称Multi-Version Concurrency Control，即多版本并发控制，主要是为了提高数据库的并发性能。以下文章都是围绕InnoDB引擎来讲，因为myIsam不支持事务。<br />
<br />同一行数据平时发生读写请求时，会上锁阻塞住。但mvcc用更好的方式去处理读—写请求，做到在发生读—写请求冲突时不用加锁。<br />
<br />这个读是指的快照读，而不是当前读，当前读是一种加锁操作，是悲观锁。<br />
<br />那它到底是怎么做到读—写不用加锁的，快照读和当前读又是什么鬼，跟着你们的贴心老哥，继续往下看。<br />
<br />**当前读、快照读都是什么鬼**<br />什么是MySQL InnoDB下的当前读和快照读？<br />
<br />当前读<br />它读取的数据库记录，都是当前最新的版本，会对当前读取的数据进行加锁，防止其他事务修改数据。是悲观锁的一种操作。<br />
<br />如下操作都是当前读：<br />

- select lock in share mode (共享锁)
- select for update (排他锁)
- update (排他锁)
- insert (排他锁)
- delete (排他锁)
- 串行化事务隔离级别


<br />快照读<br />快照读的实现是基于多版本并发控制，即MVCC，既然是多版本，那么快照读读到的数据不一定是当前最新的数据，有可能是之前历史版本的数据。<br />
<br />如下操作是快照读：<br />

- 不加锁的select操作（注：事务级别不是串行化）


<br />快照读与mvcc的关系<br />MVCCC是“维持一个数据的多个版本，使读写操作没有冲突”的一个抽象概念。<br />
<br />这个概念需要具体功能去实现，这个具体实现就是快照读。（具体实现下面讲）<br />
<br />听完贴心老哥的讲解，是不是瞬间茅厕顿开。<br />
<br />**数据库并发场景**<br />

- 读-读：不存在任何问题，也不需要并发控制
- 读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读
- 写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失


<br />**MVCC解决并发哪些问题？**<br />mvcc用来解决读—写冲突的无锁并发控制，就是为事务分配单向增长的时间戳。为每个数据修改保存一个版本，版本与事务时间戳相关联。<br />
<br />读操作只读取该事务开始前的数据库快照。<br />
<br />**解决问题如下：**<br />

- 并发读-写时：可以做到读操作不阻塞写操作，同时写操作也不会阻塞读操作。
- 解决脏读、幻读、不可重复读等事务隔离问题，但不能解决上面的写-写 更新丢失问题。


<br />因此有了下面提高并发性能的组合拳：<br />

- MVCC + 悲观锁：MVCC解决读写冲突，悲观锁解决写写冲突
- MVCC + 乐观锁：MVCC解决读写冲突，乐观锁解决写写冲突


<br />**MVCC的实现原理**<br />它的实现原理主要是**版本链，undo日志 ，Read View** 来实现的<br />
<br />**版本链**<br />我们数据库中的每行数据，除了我们肉眼看见的数据，还有几个隐藏字段。分别是`db_trx_id、db_roll_pointer、db_row_id`。<br />
<br />db_trx_id：6byte，最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID。<br />
<br />db_roll_pointer（版本链关键）：7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里）<br />
<br />db_row_id：6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以db_row_id产生一个聚簇索引。<br />
<br />实际还有一个删除flag隐藏字段, 记录被更新或删除并不代表真的删除，而是删除flag变了<br />
<br />![](https://cdn.nlark.com/yuque/0/2021/png/1758561/1616746057010-dba90751-c378-4f4e-b819-8244bb125bf4.png#align=left&display=inline&height=206&margin=%5Bobject%20Object%5D&originHeight=206&originWidth=927&size=0&status=done&style=none&width=927)<br />如上图，`db_row_id`是数据库默认为该行记录生成的唯一隐式主键，`db_trx_id`是当前操作该记录的事务ID，而`db_roll_pointer`是一个回滚指针，用于配合undo日志，指向上一个旧版本。<br />
<br />每次对数据库记录进行改动，都会记录一条undo日志，每条undo日志也都有一个`roll_pointer`属性（INSERT操作对应的undo日志没有该属性，因为该记录并没有更早的版本），可以将这些undo日志都连起来，串成一个链表，所以现在的情况就像下图一样：<br />
<br />![](https://cdn.nlark.com/yuque/0/2021/png/1758561/1616746057586-5392a359-76ef-4440-b391-419bf8ce7bb2.png#align=left&display=inline&height=565&margin=%5Bobject%20Object%5D&originHeight=565&originWidth=1080&size=0&status=done&style=none&width=1080)<br />对该记录每次更新后，都会将旧值放到一条undo日志中，就算是该记录的一个旧版本，随着更新次数的增多，所有的版本都会被roll_pointer属性连接成一个链表，我们把这个链表称之为版本链，版本链的头节点就是当前记录最新的值。另外，每个版本中还包含生成该版本时对应的事务id，这个信息很重要，在根据ReadView判断版本可见性的时候会用到。<br />
<br />undo日志<br />Undo log 主要用于记录数据被修改之前的日志，在表信息修改之前先会把数据拷贝到undo log里。<br />
<br />当事务进行回滚时可以通过undo log 里的日志进行数据还原。<br />
<br />Undo log 的用途<br />
<br />保证事务进行rollback时的原子性和一致性，当事务进行回滚的时候可以用undo log的数据进行恢复。<br />
<br />用于MVCC快照读的数据，在MVCC多版本控制中，通过读取undo log的历史版本数据可以实现不同事务版本号都拥有自己独立的快照数据版本。<br />
<br />undo log主要分为两种：<br />
<br />**insert undo log**<br />
<br />代表事务在insert新记录时产生的undo log , 只在事务回滚时需要，并且在事务提交后可以被立即丢弃<br />
<br />**update undo log（主要）**<br />
<br />事务在进行update或delete时产生的undo log ; 不仅在事务回滚时需要，在快照读时也需要；<br />
<br />所以不能随便删除，只有在快速读或事务回滚不涉及该日志时，对应的日志才会被purge线程统一清除<br />
<br />**Read View(读视图)**<br />事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照。<br />
<br />记录并维护系统当前活跃事务的ID(没有commit，当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以越新的事务，ID值越大)，是系统中当前不应该被本事务看到的其他事务id列表。<br />
<br />Read View主要是用来做可见性判断的, 即当我们某个事务执行快照读的时候，对该记录创建一个Read View读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，既可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。<br />
<br />**Read View几个属性**<br />

- trx_ids: 当前系统活跃(未提交)事务版本号集合。
- low_limit_id: 创建当前read view 时“当前系统最大事务版本号+1”。
- up_limit_id: 创建当前read view 时“系统正处于活跃事务最小版本号”
- creator_trx_id: 创建当前read view的事务版本号；


<br />**Read View可见性判断条件**<br />`db_trx_id < up_limit_id || db_trx_id == creator_trx_id（显示）`<br />
<br />如果数据事务ID小于read view中的最小活跃事务ID，则可以肯定该数据是在当前事务启之前就已经存在了的,所以可以显示。<br />
<br />或者数据的事务ID等于`creator_trx_id` ，那么说明这个数据就是当前事务自己生成的，自己生成的数据自己当然能看见，所以这种情况下此数据也是可以显示的。<br />
<br />`db_trx_id >= low_limit_id（不显示）`<br />
<br />如果数据事务ID大于read view 中的当前系统的最大事务ID，则说明该数据是在当前read view 创建之后才产生的，所以数据不显示。如果小于则进入下一个判断<br />
<br />`db_trx_id是否在活跃事务（trx_ids）中`<br />

- 不存在：则说明read view产生的时候事务已经commit了，这种情况数据则可以显示。
- 已存在：则代表我Read View生成时刻，你这个事务还在活跃，还没有Commit，你修改的数据，我当前事务也是看不见的。



## MVCC和事务隔离级别

上面所讲的Read View用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。<br />
<br />**RR、RC生成时机**<br />RC隔离级别下，是每个快照读都会生成并获取最新的Read View；<br />
<br />而在RR隔离级别下，则是同一个事务中的第一个快照读才会创建Read View, 之后的快照读获取的都是同一个Read View，之后的查询就不会重复生成了，所以一个事务的查询结果每次都是一样的。<br />
<br />解决幻读问题<br />快照读：通过MVCC来进行控制的，不用加锁。按照MVCC中规定的“语法”进行增删改查等操作，以避免幻读。<br />
<br />当前读：通过next-key锁（行锁+gap锁）来解决问题的。<br />

## RC、RR级别下的InnoDB快照读区别

在RR级别下的某个事务的对某条记录的第一次快照读会创建一个快照及Read View， 将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，还是使用的是同一个Read View，所以只要当前事务在其他事务提交更新之前使用过快照读，那么之后的快照读使用的都是同一个Read View，所以对之后的修改不可见；<br />
<br />即RR级别下，快照读生成Read View时，Read View会记录此时所有其他活动事务的快照，这些事务的修改对于当前事务都是不可见的。而早于Read View创建的事务所做的修改均是可见<br />
<br />而在RC级别下的，事务中，每次快照读都会新生成一个快照和Read View, 这就是我们在RC级别下的事务中可以看到别的事务提交的更新的原因<br />
<br />总结<br />从以上的描述中我们可以看出来，所谓的MVCC指的就是在使用READ COMMITTD、REPEATABLE READ这两种隔离级别的事务在执行普通的SEELCT操作时访问记录的版本链的过程，这样子可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。<br />

## `什么是主从复制？主从复制的作用？主从复制能够解决哪些问题`

<br />**主从复制：将主数据库中的DDL和DML操作通过二进制日志传输到从数据库上，然后这些日志被重新执行，从而使得从数据库的数据与主数据库保持一致。**<br />
<br />**主从复制的作用**<br />

1. 主数据库出现问题，可以切换到从数据库中。
1. 可进行数据库层面的读写分离。
1. 可以在从数据库上进行日常备份。


<br />**解决的问题**<br />

- 数据分布：随意开始或停止复制，并在不同地理位置分别数据备份。
- 负载均衡：降低大呢服务器的压力。
- 高可用和故障切换：帮助应用程序避免单点失败。
- 升级测试：可以使用更高版本的MySQL作为从库。



## `MySQL主从复制是怎么做的？`

<br />主从复制主要涉及三个线程：binlog线程，IO线程和SQL线程。这个过程是靠着三个线程紧密配合实现的。<br />
<br />binlog： 负责将主服务器上的数据更改写入二进制日志中。<br />
<br />IO线程：负责从主服务器上读取二进制日志，并写入从服务器的中继日志中relay log<br />
<br />SQL线程：负责读取中继日志，解析出主服务器已经执行的数据更改并在重服务器中重放。<br />

## `读写分离怎样实现（解决方案）`

<br />读写分离是依赖于主从复制的，主从复制又是为读写分离服务的。因为主从复制要求从库不能写，只能读。<br />
<br />方案1<br />
<br />使用mysql-proxy代理<br />
<br />优点：直接实现读写分离和负载均衡，不用修改代码，master和salve用一样的账号。<br />
<br />缺点：降低性能，不支持事务。<br />
<br />方案2<br />
<br />使用`AbstractRoutingDataSource+aop+annotation`在dao层决定数据源。如果采用了MyBatis，可以将读写分离放在ORM层。比如mybatis可以通过mybatis plugin拦截sql语句，所有的insert/update/delete都访问master库，所有的select 都访问salve库，这样对于dao层都是透明。 plugin实现时可以通过注解或者分析语句是读写方法来选定主从库。不过这样依然有一个问题， 也就是不支持事务， 所以我们还需要重写一下DataSourceTransactionManager， 将read-only的事务扔进读库， 其余的有读有写的扔进写库。<br />
<br />方案三<br />

## `MySQL数据备份计划`

<br />按照数据库的大小来确定，一般来说100G内的数据库可以考虑使用mysqldump来做，他更加轻巧灵活，备份时间选在业务低峰期，可以每天进行全量备份。<br />
<br />备份恢复时间<br />
<br />物理备份恢复快，逻辑备份恢复慢。<br />
<br />这里跟机器尤其是硬盘的速率有关系。<br />
<br />这里跟机器，尤其是硬盘的速率有关系，以下列举几个仅供参考<br />
<br />20G的2分钟（mysqldump）<br />
<br />80G的30分钟(mysqldump)<br />
<br />111G的30分钟（mysqldump)<br />
<br />288G的3小时（xtra)<br />
<br />3T的4小时（xtra)<br />
<br />逻辑导入时间一般是备份时间五倍以上。<br />
<br />**备份恢复是被如何处理**<br />
<br />首先在恢复之前就应该做好充足准备，避免恢复的时候出错。比如备份之后的有效性检查，权限检查，空间检查等。如果万一报错，再根据报错的提示来进行相应的调整。<br />

## `mysqldump实现原理`


```sql
mysqldump -uroot -p --skip-opt --default-character-set=utf8  --single-transaction --master-data=2 --no-autocommit -B d1> backup.sql
```

<br />mysqldump属于逻辑备份，加入`-single-transaction`选项表示：执行一致性备份。<br />
<br />后台进程会先设置`session`的事务隔离级别为RR（可重复读），之后显式开启一个事务，这样就保证了该事务里读到的数据都是事务进行时的快照。之后把表的数据读取出来。<br />
<br />`master-data=1`：表示会在备份文件中生成change master的命令；<br />
<br />`master-data=2`：表示会以注释的形式保存备份时的binlog位置信息。<br />
<br />`-B`：表示指定dump的数据库，d1是以innodb作为存储引擎的数据库。<br />
<br />执行完成后可以得到mysqld生成的general log，里面记录了mysqldump在备份过程中传给server的指令。<br />
<br />执行流程：<br />

- 连接server。（初始化session，set一些session级的变量）
- 两次关闭所有表，第二次在关闭表的同时加读锁；
- 设置隔离级别为“可重复读”，开启事务并创建快照。
- 获取binlog的位置。
- 解锁所有表。
- 对指定的库和表进行dump。



## `xrtabackup实现原理`

<br />xtrabackup属于物理备份，直接拷贝表空间，同时不断扫描产生的redo.log并保存下来。最后完成`innodb`的备份后，会做`flush engine logs`的操作，确保所有的redo log都已经落盘。这个时间点就是 `innodb`完成备份的时间点，数据文件虽然不是一致性的，但是有这段时间的 redo 就可以让数据文件达到一致性(恢复的时候做的事<br />
<br />情)。然后还需要 `flush tables with read lock`，把 `myisam`等其他引擎的表给备份出来，备份完后解锁。这样就做到了完美的热备。<br />

## `数据表损坏的修复方式有哪些`

<br />修复前将MySQL服务停止<br />
<br />打开命令行方式，然后进入到mysql的bin目录下<br />
<br />执行`myisamchk -revcover`数据库所在的路径/*.MYI<br />
<br />使用repair table 或者 OPTIMIZE table命令来修复，REPAIR TABLE table_name 修复表 OPTIMIZE TABLE table_name 优化表 REPAIR TABLE 用于修复被破坏的表。 OPTIMIZE TABLE 用于回收闲置的数据库空间，当表上的数据行被删除时，所占据的磁盘空间并没有立即被回收，使用了OPTIMIZE TABLE命令后这些空间将被回收，并且对磁盘上的数据行进行重排。<br />

## `B树和B+树有什么区别？`

<br />B树是一颗多路平衡查找树，每个节点最多有m-1个关键字，根节点最少可以只有1个关键字，非根节点至少可以有m/2个关键字。每个节点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。根节点到每个叶子结点的长度都相同。每个节点都存有索引和数据，也就是对应的key和value。<br />
<br />所以根节点的关键字数量1<=k<=m-1，非根节点的关键字数量返回：m/2<=k<=m-1。另外B树需要指定他的阶数，阶数表示一个节点最多有多少个孩子节点，一般用字母表示阶数。<br />
<br />相同点：根节点至少有一个元素，非根节点：m/2<=k<=m-1<br />
<br />不同点：<br />

- B+树有两种类型的节点：内部节点（索引节点）和叶子结点，内部节点就是非叶子结点，内部节点不存储数据，字存储索引，数据都存储在叶子结点中。
- 内部节点的key都大于等于它。叶子结点中的记录也按照key的大小排列。
- 每个叶子结点都存有相似叶子结点的指针，叶子结点本身依照关键字的代销自小向大顺序链接。
- 父节点存有右孩子的第一个元素的索引。


<br />单一节点存储的元素更多，使得查询IO的次数更少，所以使得它更适合作为数据库MySQL的底层数据结构了。<br />
<br />所有的查询都要查找到叶子结点，查询性能是稳定的。B树每个节点都可以查找到数据，所以不稳定。<br />
<br />所有的叶子节点形成了一个有序链表，更加方便查找。<br />
<br />局部性原理：当一个数据被用到时，那他附近的数据通常不就后也会使用到，程序运行期间所需要的数据通常比较集中。<br />

## `数据库为啥用B+树而不用B树？`


- B树只适合随机索引，B+既支持随机索引也支持顺序索引。
- B+树空间利用率更高，可以减少IO次数，磁盘读写代价更低。一般来说索引本身也很大，不能全部存储在内存中，因此索引往往以索引文件的形式存储在磁盘上。这样的话，索引查找过程中就要产生磁盘IO。B+树的内部节点并没有指向关键字具体信息的指针，只是作为索引使用，其内部节点比B树小，盘块能容纳的节点中的关键字数量更多，一次性读取到内存中的数量也更多。IO读写次数是影响检索效率的最大原因。
- B+树的查询效率更加稳定。B树搜索有可能会在非叶子节点结束，越靠近根节点的记录查找时间越短，只要找到关键字即可确定记录的存在，其性能等价于在关键字集合中做一次二分查找。而在B+树中，顺序检索比较明显，所及检索时，任何关键字的查找都必须走一条从根节点到叶子结点的路，所有关键字的查找路径长度相同，导致每一个关键字的查询效率相当。
- B树在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下问题。B+树的叶子结点使用指针顺序链接在一起，只要遍历叶子结点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，B树不支持这样的操作。
- 增删效率比B树高，因为叶子结点之间以链表的形式存储。



## `聚簇索引和非聚簇索引的区别`


- 聚簇索引：将数据和索引都存放在一块找到了索引也就找到了数据
- 非聚簇索引：将数据存储与索引分开，索引结构的叶子结点指向了数据的对应行，MyISAM通过key_buffer将索引先缓存到内存中，当需要访问数据时，在内存中直接搜索索引，然后通过索引找到磁盘相对应的数据，这也就是为什么索引不命中缓存时，速度慢的原因。
- 在聚簇索引上创建的索引叫做辅助索引，辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引，辅助索引叶子结点存储不再是行的物理位置而是主键。


<br />延伸问题：`哈希索引与B+索引的区别`<br />

- 哈希索引简单的说就是使用哈希算法，把键值换算成新的哈希值，检索时不需要从根节点到叶子结点查找，直接通过哈希算法确定索引的位置，速度很快。
- 对于等值查询，哈希索引明显具有绝对优势，因为只需要经过一次算法即可找到响应的键值（不出现哈希冲突）。但如果是范围查询，这时候的哈希索引就起不了作用了，因为原先键值对是有序的，经过哈希算法计算后可能就不连续了，因此没办法利用索引完成范围查询。例如排序，模糊查询其实范围查询没办法用到索引。
- 哈希索引也不支持多列联合索引的最左匹配规则。
- 在具有大量重复键的情况下，哈希索引效率也是极低的，因为存在大量的哈希冲突问题。



## `红黑树和AVL树的区别`

<br />AVL树和红黑树都是二叉查找树的优化，其性能远远好于二叉查找树。<br />

- 结构上：AVL的结构高度平衡，RBT的结构及本平衡
- 查找对比：AVL树时间度最好，最坏情况下都是O(LogN)
- RBT查找时间复杂度最好是O(logN)，最坏情况下比AVL树略差。
- 插入，删除对于：AVL插入和删除节点容易造成树的不平衡，而RBT的平衡度要求较低。在大量数据插入的情况下，RBT需要提供着色和旋转的操作来重新达到平衡的频度要小于AVL。
- 如果需要平衡处理的时候，RBT比AVL多了染色的操作，但是染色的时间复杂度在O(logN)数量级，因此变色操作也是很快速的。
- 当插入节点造成不平衡，进行平衡处理，两者最多都需要2次旋转操作，但是删除一个节点引起不平衡，进行平衡处理，AVL树最多需要logN次旋转，而RBT只需要3次，因此RBT维持平衡的操作是常数级的。
- 大量数据实验证明，RBT的性能总体好于AVL。



## `MySQl联合索引`

<br />联合索引又叫复合索引。对于复合索引:Mysql从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分。例如索引是key index (a,b,c). 可以支持**a** | **a,b**| **a,b,c** 3种组合进行查找，但不支持 b,c进行查找 .当最左侧字段是常量引用时，索引就十分有效。假设现在建立了"name，age，school"的联合索引，那么索引的排序为: 先按照name排序，如果name相同，则按照age排序，如果age的值也相等，则按照school进行排序。<br />
<br />当进行查询时，此时索引仅仅按照name严格有序，因此必须首先使用name字段进行等值查询，之后对于匹配到的列而言，其按照age字段严格有序，此时可以使用age字段用做索引查找，以此类推在建立联合索引的时候应该注意索引列的顺序，一般情况下，将查询需求频繁或者字段选择性高的列放在前面。此外可以根据特例的查询或者表结构进行单独的调整。<br />

## `前缀索引`

<br />index(field(10))，使用字段值的前10个字段建立索引，默认是使用字段的全部内容建立索引。<br />
<br />前缀索引标识度高。<br />

## `锁的分类`


- 行级锁：行级锁是MySQL中锁粒度最细的一种锁，表示只针对当前操作进行加锁。行级锁能大大减少数据库操作的冲突。加锁粒度最小，但是加锁的开销也最大。行级锁分为共享锁和排他锁。
  - 特点：开销大，加锁man，会出现死锁；锁粒度小，发生冲突的概率很低，并发度最高。
- 表级锁：表级锁是MYSQL中锁粒度最大的一种锁，表示对当前操作的整张表加锁，实现简单，资源消耗较少，被大部分MySQL引擎所支持。最常用的就是MyISAM和InnoDB都支持表级锁定。表级锁分为共享锁和独占锁（排他锁）。
  - 特点：开销小，加锁快；不会出现死锁；锁粒度大，发生锁冲突的概率最高，并发度低。
- 页级锁：页级锁是结余行级锁和表级锁中间的一种锁。表级锁速度快但是冲突高，行级锁冲突低，但是速度慢。所以折中选取了页级锁
  - 特点：加锁时间和锁的开销结余两种锁之间，会出现死锁；锁粒度在行级锁和表级锁之间，并发度一般。
- 共享锁：又叫做读锁，当用户进行读取数据的时候，对数据加上共享锁，共享锁可以同时加上多个。
- 排他锁：又叫做写锁，当用户进行数据写入的时候，对数据加上排他锁，排他锁只能加上一个。和其他锁都排斥。锁的力度取决于具体的存储引擎。



## `什么是死锁？怎么解决？`

<br />死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。<br />

## `解决死锁的方法`

<br />1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。<br />
<br />2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；<br />
<br />3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；<br />
<br />如果业务处理不好可以用分布式事务锁或者使用乐观锁<br />

## `为什么要使用视图？什么是视图？`

<br />为了提高复杂SQL语句的复用性和表操作的安全性，MySQL数据库管理系统提供了视图特性。所谓视图，本质上是一种虚拟表，在物理上是不存在的，其内容与真实的表相似，包含一系列带有名称的列和行数据。但是，视图并不在数据库中以储存的数据值形式存在。行和列数据来自定义视图的查询所引用基本表，并且在具体引用视图时动态生成。<br />
<br />视图使开发者只关心感兴趣的某些特定数据和所负责的特定任务，只能看到视图中所定义的数据，而不是视图所引用表中的数据，从而提高了数据库中数据的安全性。<br />

## `视图有哪些特点？`


- 视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。
- 视图是由基本表(实表)产生的表(虚表)。
- 视图的建立和删除不影响基本表。
- 对视图内容的更新(添加，删除和修改)直接影响基本表。
- 当视图来自多个基本表时，不允许添加和删除数据。
- 视图的操作包括创建视图，查看视图，删除视图和修改视图。



## `视图的使用场景有哪些？`

<br />视图根本用途：简化sql查询，提高开发效率。如果说还有另外一个用途那就是兼容老的表结构。<br />

- 重用SQL语句；
- 简化复杂的SQL操作。在编写查询后，可以方便的重用它而不必知道它的基本查询细节；
- 使用表的组成部分而不是整个表；
- 保护数据。可以给用户授予表的特定部分的访问权限而不是整个表的访问权限；
- 更改数据格式和表示。视图可返回与底层表的表示和格式不同的数据。



> `视图的优点`



- 查询简单化。视图能简化用户的操作
- 数据安全性。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护
- 逻辑数据独立性。视图对重构数据库提供了一定程度的逻辑独立性



> `视图的缺点`



1. 性能。数据库必须把视图的查询转化成对基本表的查询。需要花费一定的时间。
1. 修改限制。当用户试图修改视图的某些行时，数据库必须把它转化为对基本表的某些行的修改。事实上，当从视图中插入或者删除时，情况也是这样。对于简单视图来说，这是很方便的，但是，对于比较复杂的视图，可能是不可修改的。


<br />这些视图有如下特征：1.有UNIQUE等集合操作符的视图。2.有GROUP BY子句的视图。3.有诸如AVG\SUM\MAX等聚合函数的视图。 4.使用DISTINCT关键字的视图。5.连接表的视图（其中有些例外）<br />

## `什么是游标？`

<br />游标是系统为用户开设的一个数据缓冲区，存放SQL语句的执行结果，每个游标区都有一个名字。用户可以通过游标逐一获取记录并赋给主变量，交给主语言进一步处理。<br />

> `什么是存储过程？有哪些优缺点？`
> 存储过程是一个预编译的SQL语句，有点事语序模块化的设计，就是说只需要创建一次，以后就可以调用多次，如果某次操作需要执行多次SQL，使用存储过程会比单独的SQL语句执行要快。
> `优点`



- 存储过程是预编译的，执行效率高。
- 存储过程的代码直接存放于数据库中，通过存储过程名称直接调用，减少网络通讯。
- 安全性高，执行存储过程需要有一定的用户权限。
- 存储过程可以复用，减少开发人员的工作量。


<br />`缺点`<br />

- 调试比较麻烦，但是用PL/SQL Developer调试很方便。
- 移植性问题，数据库端代码当然是与数据库相关的。
- 重新编译问题，因为后端代码是运行前编译的，如果带有引用关系的对象发生改变时，受影响的存储过程、需要重新编译（不过也可以设置成运行时刻自动编译）。
- 如果大量使用存储过程，后期维护比较麻烦艰难。



> `什么是触发器？触发器的使用场景有哪些？`


<br />触发器是用户定义在关系表上的一类由事件驱动的特殊的存储过程。触发器是指一段代码，当触发某个事件时，自动执行这些代码。<br />
<br />使用场景<br />

- 可以通过数据库中的相关表实现级联更改
- 实时监控某张表中的某个字段的更改而需要做出的相应的处理。



## `MySQL中有哪些触发器？`


- Before Insert
- After Insert
- Before Update
- After Update
- Before Delete
- After Delete



## `in 和 exists的区别`

<br />MySQL中的in语言是把外表和内表做hash连接，而exists语句是对外表做loop循环，每次循环后再对内表进行查询。<br />

1. 如果查询的两张表大小相当，两者在效率上差别不大。
1. 如果两个表一个小一个大，则子查询表大的用exists，子查询表小的用in。
1. not in not exists如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引，而not exists的子查询依然能用到表上的索引。



## `怎样知道一条SQL语句有没有走索引，分析性能`

<br />MySQL提供了explain命令来查看语句的执行计划。<br />
<br />![](https://cdn.nlark.com/yuque/0/2021/png/1758561/1616746056999-533da1d8-1b08-4b37-a007-a29fca8233d2.png#align=left&display=inline&height=354&margin=%5Bobject%20Object%5D&originHeight=354&originWidth=995&size=0&status=done&style=none&width=995)<br />
<br />id有一组数字组成，表示一个查询中各个子查询的执行顺序。<br />

- id相同执行顺序由上到下
- id不同，值越大优先级越高，越先执行。
- id为null时表示一个结果集不需要使用它查询，常出现在union等查询语句中。


<br />`select_type`表示查询类型。

| id   | select_type  | 描述                                |
| ---- | ------------ | ----------------------------------- |
| 1    | SIMPLE       | 不包含任何子查询或者union查询       |
| 2    | PRIMARY      | 包含子查询最外层查询就显示为PRIMARY |
| 3    | SUBQUERY     | 在select或者where中包含的查询       |
| 4    | DERIVED      | from字句中包含的查询                |
| 5    | UNION        | 出现在UNION后的查询语句中           |
| 6    | UNION RESULT | 从UNION中获取结果集                 |



- `table`：查询数据表，当从衍生表中查询数据时会显示。x表示对应的执行计划id。
- `partitions`：表分区，创建表的时候可以指定通过哪个列进行表区分。
- `type`：访问类型，可以看出有没有走索引。（重要）
  - ALL：全表扫描。
  - index：遍历索引
  - range：索引范围查找
  - index_subquery：在子查询中使用ref。
  - unique_subquery：在子查询中使用eq_ref。
  - ref_or_null：对NULL进行索引优化
  - fulltext：全文索引
  - ref：使用非唯一索引查找数据
  - eq_ref：在join查询中使用PRIMARY KEY或者UNIQUE NOT NULL索引关联。
- `possible_keys`：可能使用的索引。不一定会使用。
- `key`：显示MySQL在查询中实际使用的索引，如果没有索引，显示为NULL。
- `TIPS`：查询中若使用了覆盖索引，则该索引仅出现在key列表中。
- `key_length`：索引长度。
- `ref`：表示上述表的链接匹配条件，哪些列或者常量被用于查找索引列上的值。
- `rows`：返回估算的结果集数目，并不是一个准确的值。
- `extra`：



1. Using index 使用覆盖索引
1. Using where 使用了用where子句来过滤结果集
1. Using filesort 使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。
1. Using temporary 使用了临时表 sql优化的目标可以参考阿里开发手册



## `一条SQL语句的执行过程（生命周期）`


1. 与应用程序创建链接
1. 解析查询语句
1. 检查用户权限
1. 优化查询
1. 执行查询
1. 存储引擎返回结果
1. 发送结果给应用程序/客户端



## `超大分页的解决方法`

<br />阿里巴巴开发手册<br />
<br />推荐：利用延迟关联或者子查询优化超多分页场景。<br />
<br />MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL改写。<br />
<br />先快速定位需要获取的id段，然后再关联：<br />

```sql
 SELECT a.* 
 FROM 表1 a, (select id from 表1 where 条件 LIMIT 100000,20 ) b 
 where a.id=b.id
```


## `慢查询日志`

<br />用于记录执行时间超过每个临界值的SQL日志，用于快速定位慢查询，为我们的优化作参考。<br />
<br />开启慢查询日志：`slow_query_log`<br />
<br />可以使用`show variables like slow_query_log`查看是否开启慢查询日志。如果状态是off，可以使用`set GLOBAL slow_query_log=on`来开启，他会在`datadir下产生一个xxx-slow.log`的文件。<br />
<br />设置临界时间<br />
<br />配置项：`long_query_time`<br />
<br />查看：`show variables like`long_query_time`<br />
<br />设置：`set long_query_time=0.5`<br />
<br />实操应该从长时间设置到短的时间，将最慢的SQL优化掉。<br />
<br />查询日志，一旦SQL超过了我们设置的临界时间就会被记录到`xxx-slow.log`中.<br />

> `慢查询出现的原因有哪些？怎样优化？`
> 在业务系统中，除了使用主键进行查询，其他的我都会在测试库上进行测试耗时，慢查询的统计主要靠运维来做。
> 慢查询出现的原因：
>
> - 首先分析SQL语句，看看是否加载了额外的数据，可能是查询到了多余的行并且抛弃掉多余的，需要对SQL进行重写。
> - 分析语句的执行计划，然后获得其使用索引的情况，之后修改语句或者修改索引，使语句尽可能命中索引。
> - 如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行横向拆分或者纵向拆分。



> `存储用户密码的散列值，应该使用char类型的字段而不是varchar`这样可以节省空间并且提高效率。



> ``



```sql
LIMIT n 等价于 LIMIT 0,n。
mysql> SELECT * FROM table LIMIT 5; //检索前 5 个记录行 
mysql> SELECT * FROM table LIMIT 95,-1; // 检索记录行 96-last. 
mysql> SELECT * FROM table LIMIT 5,10; // 检索记录行 6-15
```


## 书写SQL的建议


- 查询SQL尽量不使用select*而是指明具体字段。理由：只取需要的字段，节省资源，减少网络开销。select*进行查询时，不会使用覆盖索引，就会造成回表查询。
- 如果知道查询结果只有一条，建议使用`limit 1`。理由：加上limit1后，只要找到了对应的一条记录，就不会继续向下扫描了，效率将会大大提高。
- 如果name是唯一索引的话，是不必要加limit 1，因为limit主要是防止全表扫描，从而提高性能。如果一个语句本身不用全表扫描就没必要用limit。
- 避免在where条件后添加`or`，因为or可能会使索引失效，从而造成全表扫描。
- 优化limit分页。当偏移量最大的时候查询效率会越低。因为Mysql并非是跳过偏移量直接去取后面的数据，而是先把偏移量+要取的条数，然后再把前面偏移量这一段的数据抛弃掉再返回的。
- 优化`like`条件，将`%`放到关键字后面时候走索引的，如果放在关键字前面是不会走索引的。
- 使用where条件去限制查询数据，要什么数据就查什么数据。避免返回不必要的数据，节省开销。
- 避免在索引列上使用内置函数。这样会导致索引失效。
- 避免在where语句中对字段进行表达式（+，-, *，/）操作，这样也会导致索引失效，造成全表扫描。
- inner join，left join,right join,优先使用inner join，如果是left join，左边表的结果尽量小。因为inner join是等值连接，或许返回的行数比较少，性能较好，同理，左连接中如果左边表数据结果少，返回的行数也少。
- 避免在where语句中使用!=或者大于小于号，否者索引会失效。
- 使用联合索引，注意索引列的顺序，一般遵循最左前缀匹配原则。
- 对查询语句进行优化，考虑在where条件以及order by涉及的列上加索引。避免全表扫描。
- 如果插入数据过多，考虑批量插入。批量插入性能更好，节省时间。
- 适当的时候，采用覆盖索引。覆盖索引能够使你的SQL不需要回表，仅仅访问索引就能能够得到所需要的数据，大大提高了查询效率。
- 使用distinct关键字可以去重，但是在数据量很大，字段很多的情况下，会消耗大量系统资源，CPU时间。
- 避免创建重复索引，冗余索引，因为索引需要维护，并且在优化器优化查询的时候也需要逐个考虑是否选用，这会影响性能。
- 如果数据量很大，修改和删除时可以考虑分批删除。
- 尽量为字段设置默认值来代替null。如果把null值，换成默认值，很多时候让走索引成为可能，同时，表达意思会相对清晰一点。
- 不要超过5个以上的表连接。连表越多，编译时间和开销也更大。如果把连接表拆开可读性更高。
- 尽量用union all替换union。如果已知检索结果没有重复记录，使用union all代替union。因为union不管检索结果有没有重复都会尝试进行去重，然后再输出最终结果前进行排序。
- 一个表中的索引一般在5个以内，insert和update时可能会重建索引，所以建索引也需要慎重考虑。
- 尽量使用数字型字段，字符型会降低查询和连接的性能，并且会增加存储开销。
- 索引不适合建在有大量重复数据的字段上，如性别。
- 尽量避免向客户端返回过多的数据量。
- 当使用连接查询连接多个表时，使用表的别名，并把别名前缀定义在每一列上。
- 尽可能的使用`varchar/nvarchar`代替`char`，因为首先变长字段存储空间小，可以节省存储空间。其次对于查询来说，在一个相对较少的字段内搜索，效率更高。
- 如果字段是字符串型，where后面记得要把字段名用引号引上。否则索引失效。因为不加单引号时，是字符串跟数字的比较，它们类型不匹配，MySQL会做隐式的类型转换，把它们转换为浮点数再做比较。
- 日常开发 写SQL时，养成习惯用explain分析你写的SQL。

![](https://gitee.com/bailefolen/typora-pictures/raw/master/typora-pictures/img/1616746941957-8266c7c7-0e0c-45d4-8ece-f0203b61da40.png)
